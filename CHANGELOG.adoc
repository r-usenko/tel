= Changelog

== v2.3.6
* update go.opentelemetry.io/otel/* dependencies to 1.28.0
** replacement types / methods were taken from https://github.com/open-telemetry/opentelemetry-go/blob/main/CHANGELOG.md
* update cardinality detector, trace provider, metric provider
* add pkg/log, pkg/ringbuffer, pkg/global
* fix monitoring/health test
* update otlplog/retry/* files from https://github.com/open-telemetry/opentelemetry-go/tree/cdee7205835f4919ae1bc5f810c695fa1dd77bd4/internal/shared/otlp/retry

== v2.3.1
* HotFix: `OTEL_ENABLE`  in case of disabling - nothing should gathered at all

== v2.3.0
* add options to decrease load on collector (log message size, duplication of information for span and log, rate of flush, etc.)
* add cardinality detector for metrics (check uniqueness of label values) and traces (check uniqueness of span names)

== v2.2.4
* health check fix metrics exposure
* change health check metrics names: `up` => `service.health`, `up.status` => `service.health.status`
* Help figure out where "use null Telemetry" usage. Like tel.FromCtx(context.Background()).Debug()

== v2.2.3
* Preserve span instance in telemetry during span creation - this should help us to continue traces when it's not possible pass context of it
* `OTEL_ENABLE_COMPRESSION` - enable compression for logs, traces and metrics for grpc connections
* `OTEL_METRIC_PERIODIC_INTERVAL_SEC` - metrics interval default = 15sec
* Ctx function should return span ctx already wrapped either, UpdateTraceFields function should putSet in telemetry
* trace sampler option: WithTraceSampler allow implement own sampling strategies

== v2.2.2
* fix loosing some logs

== v2.2.1
* rename service.name => `service`
* fix LOGGING_OTEL_PROCESSOR logging with test coverage

== v2.2.0
* `LOGGING_OTEL_PROCESSOR`, `LOGGING_OTEL_CLIENT` extend logs from otel libraries
* otel: panic,fatal instantly sends to otel collector
* zlogfmt - obsolete core - we no more need to use internal logfmt. Instead try to use otelcollector attribute: loki.format with logfmt or json, just check out out docker example  file: otel-collector-config.yaml
* remove resources: `service.namespace`, "deployment.environment", "service.instance.id" - moved to collector
* remove resource: service - as it was hack for tempo referance, moved to collector
* log protocol passes correctly trace + span IDs. NOTE: this is quite unsafe implementation
* LogEncode: none not disable stderr output because this output actually if logger was not able to work properly
* LogEncode: none with OtelLog create new zap core this reduces overhead none shown stdout encoder
* Histogram custom bucket support via `WithHistogram` option

== v2.1.2
* TLS configuration: `OTEL_COLLECTOR_TLS_SERVER_NAME`, `OTEL_COLLECTOR_TLS_CA_CERT`, `OTEL_COLLECTOR_TLS_CLIENT_CERT`, `OTEL_COLLECTOR_TLS_CLIENT_KEY`
* documentation: TLS usage cases: insecure, TLS and mTLS
* migrate go.opentelemetry.io/otel/sdk v1.11.1
* because of https://github.com/open-telemetry/opentelemetry-go/commit/d091ba88e456dfd0140368bdb37beb20c7f6ed6f update migration
* zlogfmt create limits. We should protect transport from sending cumbersome msg. Currently limits hardcoded, but with possibility add them further to tel configuration

== v2.1.1
* critical fix: zap core not inherited level at copy

== v2.1.0
* example client - rework for more flexible instance view
* move managed infra `docker-compose` to ./docker folder from example
* example came up with new `hotrod`  project port from `jaeger`
* mw: http Wrap w to use our ResponseWriter methods while also exposing  other interfaces that w may implement (http.CloseNotifier,
http.Flusher, http.Hijacker, http.Pusher, io.ReaderFrom) and update gin, echo and chi libs to this fix
* rid of prometheus dependencies, not we all clean
* mw: gin fix status writing
* docker: load loki config + rid of const_labels: const_labels in prometheus, Clients should use own resource for doing that, for example via env: `OTEL_RESOURCE_ATTRIBUTES=license=COM`
* gin: redesign example
* mw: http filter now affect main mw not only httpTrace, appead option WithFilter
* plugin otelsql first version - traces and meterics
* DefaultHistogramBoundaries - allow change explicitly change histogram boundaries
* move modules, plugins to new repo https://github.com/tel-io/instrumentation
* grafana dashboards move to  https://github.com/tel-io/instrumentation/tree/main/grafana-dashboards
* configuration bug fix related to bool values
* migration github.com/d7561985/tel => github.com/tel-io/tel
* set default brunch as `main`
* monitoring feature redesign: now users should set specific option for start monitoring and provided more clear checker helpers
* monitoring metric health provider: `up` && `up.status`
* docker example migrate from prometheus to mimir
* core plugins: tracer && logger inherit log level

== v2.0.7
* full function gin mw
* mw: http mux helper
* mw: http option with path exstraction
* mw: http default span naming convention more simple and logical
* mw: grpc stream client/server helper
* not use global meter and trace provider during new instantiation of trace or meter
* documentation related to mw usage
* tel.FromCtx uses global tel instance
* minor improvements and fixes

== v2.0.6
* remove severity fields
* remove redundant duplicate
* new env `DEPLOY_ENVIRONMENT` which expose DeploymentEnvironmentKey semconv
* collector: prometheus  const_labels: stage, namespace replaced with resources,  loki: service_namespace, deployment_environment

== v2.0.5
* grafana feature `tracesToLogs`: ref. from trace => logs
* resources: add `service` which duplicate `ServiceNameKey` from semconv. We can't rid of `ServiceNameKey` because of `tempo` search feature. Furthermore `tracesToLogs` uses  `Loki`  labels which not support dot. That's why we can use simple `service` label and that's why we use for now `service` as label for loki.
* somconv 1,7.0 => 1.10.0
* mw: http extend metrics with `method`, `url`, `status` and `code` fields
* mw: nats add metrics
* grafana/dashboard: nats - full feature reach
* grafana/dashboard: http - redesign
* managed dashboards for `HTTP`
* example: grafana load all managed dashboards
* example: WIP nats service

== v2.0.4
* mw: grpc module move up to OTLP including metrics nad traces
* mw: http move to options
* grafana/dashboard: grpc
* more complex example include

== v2.0.3
* Rid of errors /dev/stderr during closer because of sync - we use OTEL Logger closer for final sync now
* Allow disable OTEL prapagation `OTEL_ENABLE`
* `NewSimple` constructor without OTEL
* Implement options more gracefully OTEL initialization
* Monitor uses options flow for setup and add as composition to Telemetry for `AddHealthChecker` health attach

